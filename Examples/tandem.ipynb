{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pymiediff as pmd\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_wavelength = 380  # nm\n",
    "ending_wavelength = 750  # nm\n",
    "\n",
    "N_pt_test = 250\n",
    "\n",
    "wl = torch.linspace(\n",
    "    starting_wavelength,\n",
    "    ending_wavelength,\n",
    "    N_pt_test,\n",
    "    dtype=torch.double,\n",
    "    requires_grad=False,\n",
    ")\n",
    "\n",
    "k0 = 2 * torch.pi / wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range of starting parameter combinations\n",
    "r_c_min, r_c_max = 10.0, 20.0\n",
    "r_s_min, r_s_max = 45.0, 55.0\n",
    "n_c_min, n_c_max = 2.0 + 0.1j, 2.0 + 0.1j\n",
    "n_s_min, n_s_max = 5.0 + 0.2j, 5.0 + 0.2j\n",
    "\n",
    "# define number of starting parameter combinations\n",
    "NumComb = 1000\n",
    "\n",
    "r_c, r_s, n_c, n_s = pmd.seedComb(\n",
    "    r_c_min,\n",
    "    r_c_max,\n",
    "    r_s_min,\n",
    "    r_s_max,\n",
    "    n_c_min,\n",
    "    n_c_max,\n",
    "    n_s_min,\n",
    "    n_s_max,\n",
    "    NumComb=NumComb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_section = np.zeros((NumComb, N_pt_test), dtype=np.float32)\n",
    "\n",
    "# # Compute cross-section iteratively\n",
    "# for i in range(NumComb):\n",
    "#     cross_section[i] = pmd.farfield.cross_sections(\n",
    "#         k0=k0,\n",
    "#         r_c=r_c[i],\n",
    "#         eps_c=n_c[i]**2,\n",
    "#         r_s=r_s[i],\n",
    "#         eps_s=n_s[i]**2,\n",
    "#         eps_env=1,\n",
    "#     )['q_sca']\n",
    "#     if i % 50 == 0:\n",
    "#         print(f\"{i}/{NumComb}\")\n",
    "\n",
    "# # Save to HDF5 file\n",
    "# h5_path = \"dataset.h5\"\n",
    "# with h5py.File(h5_path, \"w\") as f:\n",
    "#     f.create_dataset(\"r_c\", data=r_c)\n",
    "#     f.create_dataset(\"r_s\", data=r_s)\n",
    "#     f.create_dataset(\"n_c\", data=n_c)\n",
    "#     f.create_dataset(\"n_s\", data=n_s)\n",
    "#     f.create_dataset(\"cross_section\", data=cross_section)\n",
    "\n",
    "# print(f\"Dataset saved to {h5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_28992\\570082199.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TorchStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        data = torch.tensor(data, dtype=torch.double)\n",
    "        self.mean = data.mean(dim=0)\n",
    "        self.std = data.std(dim=0)\n",
    "        self.std[self.std == 0] = 1.0  # Avoid division by zero\n",
    "\n",
    "    def transform(self, data):\n",
    "        data = torch.tensor(data, dtype=torch.double)\n",
    "        data = data.clone().detach().requires_grad_(True) #torch.tensor(data, dtype=torch.double) #\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        data = torch.tensor(data, dtype=torch.double)\n",
    "        data = data.clone().detach().requires_grad_(True) #torch.tensor(data, dtype=torch.double)\n",
    "        return data * self.std + self.mean\n",
    "\n",
    "class CoreShellDataset(Dataset):\n",
    "    def __init__(self, h5_file, fit_scalers=True, x_scaler=None, y_scaler=None):\n",
    "        super().__init__()\n",
    "        self.h5_file = h5_file\n",
    "\n",
    "        # Open the file to get dataset sizes (but don't keep it open)\n",
    "        with h5py.File(h5_file, \"r\") as f:\n",
    "            self.length = len(f[\"r_c\"])\n",
    "            if fit_scalers:\n",
    "                # Load all data to fit scalers\n",
    "                x_data = np.stack([f[\"r_c\"][:], f[\"r_s\"][:], f[\"n_c\"][:].real, f[\"n_c\"][:].imag, f[\"n_s\"][:].real, f[\"n_s\"][:].imag], axis=1)\n",
    "                y_data = f[\"cross_section\"][:]\n",
    "\n",
    "                self.x_scaler = TorchStandardScaler()\n",
    "                self.y_scaler = TorchStandardScaler()\n",
    "\n",
    "                self.x_scaler.fit(torch.tensor(x_data, dtype=torch.double))\n",
    "                self.y_scaler.fit(torch.tensor(y_data, dtype=torch.double))\n",
    "            else:\n",
    "                self.x_scaler = x_scaler\n",
    "                self.y_scaler = y_scaler\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, \"r\") as f:\n",
    "            r_c = f[\"r_c\"][idx]\n",
    "            r_s = f[\"r_s\"][idx]\n",
    "            n_c_re = f[\"n_c\"][idx].real\n",
    "            n_c_im = f[\"n_c\"][idx].imag\n",
    "            n_s_re = f[\"n_s\"][idx].real\n",
    "            n_s_im = f[\"n_s\"][idx].imag\n",
    "            cross_section = f[\"cross_section\"][idx]\n",
    "\n",
    "        x = np.array([r_c, r_s, n_c_re, n_c_im, n_s_re, n_s_im]).reshape(1, -1)\n",
    "        y = np.array(cross_section).reshape(1, -1)\n",
    "\n",
    "        # Scale data using PyTorch scaler\n",
    "        x = self.x_scaler.transform(x).flatten()\n",
    "        y = self.y_scaler.transform(cross_section.reshape(1, -1)).flatten()\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# Usage example\n",
    "h5_path = \"dataset.h5\"\n",
    "dataset = CoreShellDataset(h5_path)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = dataset.x_scaler\n",
    "y_scaler = dataset.y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled x: tensor([[ -4.9413, -17.4347,  -0.5000,   1.9000,  -3.5000,   1.8000]],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Original x: tensor([[0.5000, 0.7000, 1.5000, 2.0000, 1.5000, 2.0000]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Scaled y: tensor([[-3.8395e+00, -3.7576e+00, -3.4057e+00, -3.9135e+00, -2.4388e+00,\n",
      "         -2.4430e+00, -2.3811e+00, -2.3720e+00, -3.1418e+00, -2.1628e+00,\n",
      "         -2.4879e+00, -2.9461e+00, -2.8374e+00, -3.2904e+00, -2.2517e+00,\n",
      "         -3.2780e+00, -2.4634e+00, -2.3195e+00, -3.1900e+00, -3.6180e+00,\n",
      "         -2.4164e+00, -2.0445e+00, -3.3728e+00, -2.2635e+00, -2.0780e+00,\n",
      "         -2.7076e+00, -2.1123e+00, -4.2071e+00, -3.2919e+00, -4.1265e+00,\n",
      "         -4.9286e+00, -3.6278e+00, -2.2657e+00, -3.2137e+00, -3.6881e+00,\n",
      "         -5.0991e+00, -6.2507e+00, -5.8374e+00, -4.9642e+00, -7.1326e+00,\n",
      "         -5.9458e+00, -7.9513e+00, -4.6823e+00, -6.9562e+00, -5.4900e+00,\n",
      "         -3.1422e+00, -3.6788e+00, -7.1758e+00, -3.7533e+00, -6.2599e+00,\n",
      "         -2.6354e+00, -3.3465e+00, -4.9286e+00, -3.0128e+00, -2.6233e+00,\n",
      "         -3.9862e+00, -3.1230e+00, -2.8859e+00, -3.8820e+00, -2.9626e+00,\n",
      "         -3.2834e+00, -2.4757e+00, -5.2088e+00, -3.5865e+00, -3.5305e+00,\n",
      "         -5.2277e+00, -4.4262e+00, -3.1578e+00, -4.8526e+00, -2.9797e+00,\n",
      "         -3.7397e+00, -3.6050e+00, -4.0303e+00, -4.0600e+00, -3.0592e+00,\n",
      "         -1.9311e+00, -2.6096e+00, -2.2865e+00, -2.1775e+00, -2.1856e+00,\n",
      "         -3.8791e+00, -2.6622e+00, -1.7530e+00, -1.7271e+00, -2.4403e+00,\n",
      "         -1.8507e+00, -2.6505e+00, -3.1675e+00, -3.0669e+00, -2.3223e+00,\n",
      "         -2.1288e+00, -2.7540e+00, -1.1609e+00, -1.0185e+00, -1.3587e+00,\n",
      "         -1.7699e+00, -9.8871e-01, -1.5399e+00, -1.8079e+00, -1.9944e+00,\n",
      "         -1.5715e+00, -8.3605e-01, -1.5319e+00, -8.6063e-01, -1.6564e+00,\n",
      "         -1.0423e+00, -1.6354e+00, -1.0993e+00, -4.7144e-01, -5.8557e-01,\n",
      "         -7.3905e-01, -1.0564e+00, -1.1308e+00, -1.9864e-01, -3.2437e-01,\n",
      "         -8.5618e-01, -1.0279e+00, -1.0590e+00, -6.6172e-01, -7.9669e-02,\n",
      "         -9.8639e-01, -4.5092e-01, -1.3027e+00, -2.3706e-01,  6.6194e-03,\n",
      "         -1.0199e+00, -1.0295e+00, -1.9118e-01, -1.1358e+00,  5.7731e-01,\n",
      "          3.9472e-01, -9.2080e-01, -4.6811e-01,  2.1110e-01, -4.9394e-02,\n",
      "          1.4520e-01, -1.0291e+00,  5.8086e-01, -8.0631e-01,  1.2659e-01,\n",
      "          1.4662e+00,  1.3987e+00,  4.9140e-01,  8.4783e-01,  1.1786e+00,\n",
      "         -1.1558e+00,  2.3599e+00,  9.5995e-01,  6.5008e-01,  8.1738e-01,\n",
      "         -1.4324e+00, -1.7014e+00, -4.4499e-01,  3.3707e+00,  6.8314e-01,\n",
      "         -8.4582e-01,  1.9886e+00,  4.4225e+00,  4.1431e+00,  6.0269e-01,\n",
      "          1.9511e+00,  1.7827e+00,  5.4803e+00,  6.1790e+00,  6.1128e+00,\n",
      "         -2.5020e-01, -1.5164e+00,  2.2821e+00,  1.2231e+00,  6.4855e+00,\n",
      "          6.0753e+00,  4.7546e+00,  1.6207e+00,  8.0912e+00, -1.2356e+00,\n",
      "          9.6132e+00,  9.8976e+00,  1.6558e+00,  1.2305e+00, -1.4918e+00,\n",
      "          9.7542e+00,  1.0591e+01,  8.4878e+00, -4.5360e-01, -1.7550e+00,\n",
      "          1.1774e+01,  9.6215e+00,  5.5627e+00,  9.1431e+00,  3.6554e+00,\n",
      "          1.2589e+01,  3.5639e+00, -1.2620e+00, -1.5599e+00, -1.8115e+00,\n",
      "          2.1624e-01, -1.7765e-01,  1.6920e+00,  1.0477e+01,  3.0573e+00,\n",
      "          8.0258e+00,  9.0327e+00,  7.5997e+00,  1.1474e+01,  6.1885e+00,\n",
      "         -5.9987e-01,  7.6583e+00,  1.0250e+01,  1.7731e+01,  9.5591e+00,\n",
      "          1.1558e+01,  1.4965e+01,  1.1173e+01,  9.9144e+00,  2.4006e+01,\n",
      "          2.1691e+01,  1.8038e+01,  1.3887e+01,  6.6700e+00,  8.1110e+00,\n",
      "          2.5664e+00,  1.2475e+01,  8.8057e+00,  2.5979e+01,  8.5997e+00,\n",
      "          6.6790e+00,  9.2811e+00,  1.8334e+01,  1.2478e+01,  4.4028e+00,\n",
      "          1.3953e+01,  1.3429e+01,  1.8788e+01,  5.5994e+00,  2.8411e+00,\n",
      "          2.2823e+01,  3.1168e+01,  1.8379e+01,  1.3523e+01,  2.3744e+01,\n",
      "          2.4899e+01,  8.1524e+00,  3.5712e+01,  2.1191e+01,  1.3605e+01,\n",
      "          1.0955e+01,  7.4357e+00,  2.5088e+01,  1.9286e+01,  3.0829e+01]],\n",
      "       dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Original y: tensor([[1.3713e-01, 1.8235e-01, 3.7905e-01, 6.4285e-02, 9.1017e-01, 8.8464e-01,\n",
      "         8.9651e-01, 8.7676e-01, 3.9972e-01, 9.5101e-01, 7.3883e-01, 4.5391e-01,\n",
      "         5.0226e-01, 2.3360e-01, 8.1212e-01, 2.3677e-01, 6.8236e-01, 7.5782e-01,\n",
      "         3.0705e-01, 1.0524e-01, 7.1858e-01, 9.0461e-01, 2.9691e-01, 8.1916e-01,\n",
      "         9.1092e-01, 6.6057e-01, 9.1951e-01, 1.3284e-01, 5.1617e-01, 2.5906e-01,\n",
      "         4.0340e-02, 5.1562e-01, 9.6869e-01, 7.1776e-01, 6.2411e-01, 3.0276e-01,\n",
      "         8.2239e-02, 2.4930e-01, 5.0176e-01, 9.6464e-02, 3.9151e-01, 4.4590e-02,\n",
      "         6.9234e-01, 2.8291e-01, 5.5305e-01, 9.7914e-01, 8.6301e-01, 1.4654e-01,\n",
      "         7.9850e-01, 2.2487e-01, 9.8820e-01, 7.9830e-01, 3.7932e-01, 8.3122e-01,\n",
      "         9.1550e-01, 5.2917e-01, 7.5238e-01, 8.1073e-01, 5.1708e-01, 7.8169e-01,\n",
      "         6.8772e-01, 9.2871e-01, 1.2370e-01, 6.0781e-01, 6.2785e-01, 1.2749e-01,\n",
      "         3.6361e-01, 7.3641e-01, 2.2101e-01, 7.7264e-01, 5.2462e-01, 5.4440e-01,\n",
      "         3.8229e-01, 3.3879e-01, 6.3598e-01, 9.9150e-01, 7.2622e-01, 8.1040e-01,\n",
      "         8.1920e-01, 7.8352e-01, 7.2567e-02, 5.1785e-01, 8.6147e-01, 8.4095e-01,\n",
      "         4.8755e-01, 7.1845e-01, 3.0229e-01, 3.0117e-03, 2.1271e-04, 3.3193e-01,\n",
      "         3.9145e-01, 1.2378e-02, 8.4701e-01, 8.9934e-01, 6.7544e-01, 4.0103e-01,\n",
      "         8.3629e-01, 4.7026e-01, 2.6903e-01, 1.1394e-01, 3.5016e-01, 8.0118e-01,\n",
      "         3.1072e-01, 7.3321e-01, 1.6224e-01, 5.5598e-01, 1.1480e-01, 4.6307e-01,\n",
      "         8.8218e-01, 7.7768e-01, 6.4459e-01, 3.9440e-01, 3.1834e-01, 9.5981e-01,\n",
      "         8.4666e-01, 4.4898e-01, 3.0903e-01, 2.6955e-01, 5.2288e-01, 8.9238e-01,\n",
      "         2.7140e-01, 6.0186e-01, 4.7149e-02, 6.9260e-01, 8.1464e-01, 1.9717e-01,\n",
      "         1.8519e-01, 6.2988e-01, 1.2040e-01, 9.6980e-01, 8.4741e-01, 2.1657e-01,\n",
      "         4.1025e-01, 6.8097e-01, 5.5299e-01, 6.0801e-01, 1.6291e-01, 7.1598e-01,\n",
      "         2.3547e-01, 5.2244e-01, 9.0233e-01, 8.4774e-01, 5.7094e-01, 6.4272e-01,\n",
      "         7.0071e-01, 1.3142e-01, 9.1406e-01, 5.8223e-01, 4.9992e-01, 5.1676e-01,\n",
      "         8.2648e-02, 3.7073e-02, 2.5531e-01, 8.7438e-01, 4.2250e-01, 1.8015e-01,\n",
      "         5.8914e-01, 9.1124e-01, 8.4431e-01, 3.5910e-01, 5.1884e-01, 4.8426e-01,\n",
      "         9.0222e-01, 9.5423e-01, 9.1910e-01, 2.2187e-01, 8.8634e-02, 4.6476e-01,\n",
      "         3.5186e-01, 8.3421e-01, 7.7542e-01, 6.3973e-01, 3.5657e-01, 8.8639e-01,\n",
      "         1.1095e-01, 9.6361e-01, 9.6236e-01, 3.2422e-01, 2.8695e-01, 8.8291e-02,\n",
      "         8.6722e-01, 9.0483e-01, 7.4626e-01, 1.5332e-01, 6.9144e-02, 9.0377e-01,\n",
      "         7.5537e-01, 5.0068e-01, 6.9824e-01, 3.7422e-01, 8.6290e-01, 3.5630e-01,\n",
      "         9.3312e-02, 7.6913e-02, 6.3493e-02, 1.6499e-01, 1.4335e-01, 2.3192e-01,\n",
      "         6.4540e-01, 2.8875e-01, 5.1173e-01, 5.4871e-01, 4.7656e-01, 6.3724e-01,\n",
      "         4.0150e-01, 1.1051e-01, 4.5010e-01, 5.4853e-01, 8.3898e-01, 5.0494e-01,\n",
      "         5.7476e-01, 6.9599e-01, 5.4355e-01, 4.8925e-01, 9.9447e-01, 8.9707e-01,\n",
      "         7.5535e-01, 6.0041e-01, 3.4492e-01, 3.8896e-01, 1.9933e-01, 5.2181e-01,\n",
      "         3.9620e-01, 9.3857e-01, 3.7948e-01, 3.1504e-01, 3.9070e-01, 6.5902e-01,\n",
      "         4.7612e-01, 2.3278e-01, 5.0701e-01, 4.8566e-01, 6.3110e-01, 2.5536e-01,\n",
      "         1.7639e-01, 7.1782e-01, 9.3318e-01, 5.8262e-01, 4.4845e-01, 7.0765e-01,\n",
      "         7.2878e-01, 2.9729e-01, 9.8153e-01, 6.1205e-01, 4.2019e-01, 3.5164e-01,\n",
      "         2.6396e-01, 6.7623e-01, 5.3372e-01, 7.9306e-01]], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_28992\\570082199.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "# Example of using the scalers on new data\n",
    "new_x = np.array([[0.5, 0.7, 1.5, 2.0, 1.5, 2.0]])\n",
    "scaled_x = x_scaler.transform(new_x)\n",
    "original_x = x_scaler.inverse_transform(scaled_x)\n",
    "\n",
    "new_y = np.random.rand(1, 250)  # Example y data with size 20\n",
    "scaled_y = y_scaler.transform(new_y)\n",
    "original_y = y_scaler.inverse_transform(scaled_y)\n",
    "\n",
    "print(\"Scaled x:\", scaled_x)\n",
    "print(\"Original x:\", original_x)\n",
    "print(\"Scaled y:\", scaled_y)\n",
    "print(\"Original y:\", original_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=250, output_dim=6, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "test = torch.rand((32, 4))\n",
    "test_shape = test.shape\n",
    "print(test_shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def vector_batch(x_pred):\n",
    "\n",
    "\n",
    "    batch_shape = x_pred.shape\n",
    "    # [r_c, r_s, n_c_re, n_c_im, n_s_re, n_s_im]\n",
    "    y_pred_temp = []\n",
    "\n",
    "    for i in range(batch_shape[0]):\n",
    "        x_batch = x_pred[i, :]\n",
    "        r_c_i, r_s_i, n_c_re_i, n_c_im_i, n_s_re_i, n_s_im_i = x_batch[0], x_batch[1], x_batch[2], x_batch[3], x_batch[4], x_batch[5]\n",
    "\n",
    "        #print(\"x\", x_batch)\n",
    "\n",
    "        y_batch = pmd.farfield.cross_sections(\n",
    "            k0=k0,\n",
    "            r_c=r_c_i,\n",
    "            eps_c=(n_c_re_i+1j*n_c_im_i) ** 2,\n",
    "            r_s=r_s_i,\n",
    "            eps_s=(n_s_re_i+1j*n_s_im_i) ** 2,\n",
    "            eps_env=1,\n",
    "        )[\"q_sca\"]\n",
    "\n",
    "\n",
    "\n",
    "        # y_batch = y_batch.to(dtype=torch.double)  # Set dtype\n",
    "        # y_batch[torch.isnan(y_batch)] = 0  # Replace NaNs with zero\n",
    "\n",
    "        #print(\"y\", y_batch[:10])\n",
    "        y_pred_temp.append(y_batch)\n",
    "\n",
    "    # print(y_pred_temp)\n",
    "\n",
    "    y_pred = torch.stack(y_pred_temp)\n",
    "\n",
    "\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=20, lr=1e-5, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    model.to(device)\n",
    "    model.double()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Inverse model\n",
    "            x_pred = model(y_batch)\n",
    "            #print(x_pred.shape)\n",
    "            # Forward model\n",
    "\n",
    "            x_pred_scaled = x_scaler.inverse_transform(x_pred)\n",
    "\n",
    "            y_pred = vector_batch(x_pred_scaled)#\n",
    "\n",
    "            y_pred_scaled = y_scaler.transform(y_pred)\n",
    "            # print(\"y test\", y_batch[0, :10])\n",
    "            # print(\"vVv Inverse network vVv\")\n",
    "            # print(\"x pred\", x_pred_scaled[0, :])\n",
    "            # print(\"vVv Forward Mie solver vVv\")\n",
    "            # print(\"y pred\", y_pred[0, :10])\n",
    "\n",
    "            loss = criterion(y_pred_scaled, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_28992\\570082199.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "h5_path = \"dataset.h5\"\n",
    "\n",
    "train_dataset = CoreShellDataset(h5_path)\n",
    "# scaler = train_dataset.scaler  # Save scaler for later use\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking about 1min 30s on my laptop per epoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_28992\\570082199.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n",
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_28992\\570082199.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mlp_model \u001b[38;5;241m=\u001b[39m MLP()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 59\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, num_epochs, lr, device)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#print(x_pred.shape)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Forward model\u001b[39;00m\n\u001b[0;32m     57\u001b[0m x_pred_scaled \u001b[38;5;241m=\u001b[39m x_scaler\u001b[38;5;241m.\u001b[39minverse_transform(x_pred)\n\u001b[1;32m---> 59\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mvector_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pred_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     61\u001b[0m y_pred_scaled \u001b[38;5;241m=\u001b[39m y_scaler\u001b[38;5;241m.\u001b[39mtransform(y_pred)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# print(\"y test\", y_batch[0, :10])\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"vVv Inverse network vVv\")\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# print(\"x pred\", x_pred_scaled[0, :])\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# print(\"vVv Forward Mie solver vVv\")\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# print(\"y pred\", y_pred[0, :10])\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m, in \u001b[0;36mvector_batch\u001b[1;34m(x_pred)\u001b[0m\n\u001b[0;32m     10\u001b[0m r_c_i, r_s_i, n_c_re_i, n_c_im_i, n_s_re_i, n_s_im_i \u001b[38;5;241m=\u001b[39m x_batch[\u001b[38;5;241m0\u001b[39m], x_batch[\u001b[38;5;241m1\u001b[39m], x_batch[\u001b[38;5;241m2\u001b[39m], x_batch[\u001b[38;5;241m3\u001b[39m], x_batch[\u001b[38;5;241m4\u001b[39m], x_batch[\u001b[38;5;241m5\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#print(\"x\", x_batch)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[43mpmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfarfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_sections\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_c_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_c_re_i\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn_c_im_i\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_s_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_s_re_i\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mn_s_im_i\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_sca\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# y_batch = y_batch.to(dtype=torch.double)  # Set dtype\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# y_batch[torch.isnan(y_batch)] = 0  # Replace NaNs with zero\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#print(\"y\", y_batch[:10])\u001b[39;00m\n\u001b[0;32m     29\u001b[0m y_pred_temp\u001b[38;5;241m.\u001b[39mappend(y_batch)\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\farfield.py:47\u001b[0m, in \u001b[0;36mcross_sections\u001b[1;34m(k0, r_c, eps_c, r_s, eps_s, eps_env, an, bn, n_max)\u001b[0m\n\u001b[0;32m     45\u001b[0m m_c \u001b[38;5;241m=\u001b[39m n_c \u001b[38;5;241m/\u001b[39m n_env\n\u001b[0;32m     46\u001b[0m m_s \u001b[38;5;241m=\u001b[39m n_s \u001b[38;5;241m/\u001b[39m n_env\n\u001b[1;32m---> 47\u001b[0m a_n \u001b[38;5;241m=\u001b[39m \u001b[43man\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m b_n \u001b[38;5;241m=\u001b[39m bn(x, y, n, m_c, m_s)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# - geometric cross section\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\coreshell.py:25\u001b[0m, in \u001b[0;36man\u001b[1;34m(x, y, n, m1, m2)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21man\u001b[39m(x, y, n, m1, m2):\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m---> 25\u001b[0m         psi(y, n) \u001b[38;5;241m*\u001b[39m (psi_der(m2 \u001b[38;5;241m*\u001b[39m y, n) \u001b[38;5;241m-\u001b[39m \u001b[43mAn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m chi_der(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;241m-\u001b[39m m2 \u001b[38;5;241m*\u001b[39m psi_der(y, n) \u001b[38;5;241m*\u001b[39m (psi(m2 \u001b[38;5;241m*\u001b[39m y, n) \u001b[38;5;241m-\u001b[39m An(x, n, m1, m2) \u001b[38;5;241m*\u001b[39m chi(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     27\u001b[0m     ) \u001b[38;5;241m/\u001b[39m (\n\u001b[0;32m     28\u001b[0m         xi(y, n) \u001b[38;5;241m*\u001b[39m (psi_der(m2 \u001b[38;5;241m*\u001b[39m y, n) \u001b[38;5;241m-\u001b[39m An(x, n, m1, m2) \u001b[38;5;241m*\u001b[39m chi_der(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;241m-\u001b[39m m2 \u001b[38;5;241m*\u001b[39m xi_der(y, n) \u001b[38;5;241m*\u001b[39m (psi(m2 \u001b[38;5;241m*\u001b[39m y, n) \u001b[38;5;241m-\u001b[39m An(x, n, m1, m2) \u001b[38;5;241m*\u001b[39m chi(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     30\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\coreshell.py:9\u001b[0m, in \u001b[0;36mAn\u001b[1;34m(x, n, m1, m2)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mAn\u001b[39m(x, n, m1, m2):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m         m2 \u001b[38;5;241m*\u001b[39m psi(m2 \u001b[38;5;241m*\u001b[39m x, n) \u001b[38;5;241m*\u001b[39m psi_der(m1 \u001b[38;5;241m*\u001b[39m x, n)\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;241m-\u001b[39m m1 \u001b[38;5;241m*\u001b[39m psi_der(m2 \u001b[38;5;241m*\u001b[39m x, n) \u001b[38;5;241m*\u001b[39m psi(m1 \u001b[38;5;241m*\u001b[39m x, n)\n\u001b[0;32m      7\u001b[0m     ) \u001b[38;5;241m/\u001b[39m (\n\u001b[0;32m      8\u001b[0m         m2 \u001b[38;5;241m*\u001b[39m chi(m2 \u001b[38;5;241m*\u001b[39m x, n) \u001b[38;5;241m*\u001b[39m psi_der(m1 \u001b[38;5;241m*\u001b[39m x, n)\n\u001b[1;32m----> 9\u001b[0m         \u001b[38;5;241m-\u001b[39m m1 \u001b[38;5;241m*\u001b[39m \u001b[43mchi_der\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m psi(m1 \u001b[38;5;241m*\u001b[39m x, n)\n\u001b[0;32m     10\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\special.py:250\u001b[0m, in \u001b[0;36mchi_der\u001b[1;34m(z, n)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchi_der\u001b[39m(z, n):\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mYn(n, z) \u001b[38;5;241m-\u001b[39m z \u001b[38;5;241m*\u001b[39m \u001b[43mdYn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\special.py:221\u001b[0m, in \u001b[0;36mdYn\u001b[1;34m(n, z)\u001b[0m\n\u001b[0;32m    219\u001b[0m n \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(n, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\n\u001b[0;32m    220\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(z)\n\u001b[1;32m--> 221\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_AutoDiffdYn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\okcj1g19\\AppData\\Local\\anaconda3\\envs\\pyMieDiff\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\special.py:178\u001b[0m, in \u001b[0;36m_AutoDiffdYn.forward\u001b[1;34m(n, z)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(n, z):\n\u001b[0;32m    177\u001b[0m     n_np, z_np \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), z\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mspherical_yn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderivative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\okcj1g19\\AppData\\Local\\anaconda3\\envs\\pyMieDiff\\Lib\\site-packages\\scipy\\special\\_spherical_bessel.py:178\u001b[0m, in \u001b[0;36mspherical_yn\u001b[1;34m(n, z, derivative)\u001b[0m\n\u001b[0;32m    176\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m derivative:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_spherical_yn_d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _spherical_yn(n, z)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_model = MLP()\n",
    "train_model(mlp_model, dataloader, num_epochs=50, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from the dataset\n",
    "x_sample, y_sample = train_dataset[0]  # Example input\n",
    "x_sample = x_sample.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Run inference\n",
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = mlp_model(x_sample)\n",
    "\n",
    "# Convert prediction back to original scale\n",
    "y_pred_original = scaler.inverse_transform(y_pred.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyMieDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
