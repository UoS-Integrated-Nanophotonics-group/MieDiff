{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pymiediff as pmd\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_wavelength = 380  # nm\n",
    "ending_wavelength = 750  # nm\n",
    "\n",
    "N_pt_test = 250\n",
    "\n",
    "wl = torch.linspace(\n",
    "    starting_wavelength,\n",
    "    ending_wavelength,\n",
    "    N_pt_test,\n",
    "    dtype=torch.double,\n",
    "    requires_grad=False,\n",
    ")\n",
    "\n",
    "k0 = 2 * torch.pi / wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range of starting parameter combinations\n",
    "r_c_min, r_c_max = 10.0, 20.0\n",
    "r_s_min, r_s_max = 45.0, 55.0\n",
    "n_c_min, n_c_max = 2.0 + 0.1j, 2.0 + 0.1j\n",
    "n_s_min, n_s_max = 5.0 + 0.2j, 5.0 + 0.2j\n",
    "\n",
    "# define number of starting parameter combinations\n",
    "NumComb = 1000\n",
    "\n",
    "r_c, r_s, n_c, n_s = pmd.seedComb(\n",
    "    r_c_min,\n",
    "    r_c_max,\n",
    "    r_s_min,\n",
    "    r_s_max,\n",
    "    n_c_min,\n",
    "    n_c_max,\n",
    "    n_s_min,\n",
    "    n_s_max,\n",
    "    NumComb=NumComb,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_section = np.zeros((NumComb, N_pt_test), dtype=np.float32)\n",
    "\n",
    "# # Compute cross-section iteratively\n",
    "# for i in range(NumComb):\n",
    "#     cross_section[i] = pmd.farfield.cross_sections(\n",
    "#         k0=k0,\n",
    "#         r_c=r_c[i],\n",
    "#         eps_c=n_c[i]**2,\n",
    "#         r_s=r_s[i],\n",
    "#         eps_s=n_s[i]**2,\n",
    "#         eps_env=1,\n",
    "#     )['q_sca']\n",
    "#     if i % 50 == 0:\n",
    "#         print(f\"{i}/{NumComb}\")\n",
    "\n",
    "# # Save to HDF5 file\n",
    "# h5_path = \"dataset.h5\"\n",
    "# with h5py.File(h5_path, \"w\") as f:\n",
    "#     f.create_dataset(\"r_c\", data=r_c)\n",
    "#     f.create_dataset(\"r_s\", data=r_s)\n",
    "#     f.create_dataset(\"n_c\", data=n_c)\n",
    "#     f.create_dataset(\"n_s\", data=n_s)\n",
    "#     f.create_dataset(\"cross_section\", data=cross_section)\n",
    "\n",
    "# print(f\"Dataset saved to {h5_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_32088\\1531130095.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TorchStandardScaler:\n",
    "    def __init__(self):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, data):\n",
    "        data = torch.tensor(data, dtype=torch.double)\n",
    "        self.mean = data.mean(dim=0)\n",
    "        self.std = data.std(dim=0)\n",
    "        self.std[self.std == 0] = 1.0  # Avoid division by zero\n",
    "\n",
    "    def transform(self, data):\n",
    "        data = torch.tensor(data, dtype=torch.double)\n",
    "        data = data.clone().detach().requires_grad_(True) #torch.tensor(data, dtype=torch.double) #\n",
    "        return (data - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, data):\n",
    "        data = torch.tensor(data, dtype=torch.double)\n",
    "        data = data.clone().detach().requires_grad_(True) #torch.tensor(data, dtype=torch.double)\n",
    "        return data * self.std + self.mean\n",
    "\n",
    "class CoreShellDataset(Dataset):\n",
    "    def __init__(self, h5_file, fit_scalers=True, x_scaler=None, y_scaler=None):\n",
    "        super().__init__()\n",
    "        self.h5_file = h5_file\n",
    "\n",
    "        # Open the file to get dataset sizes (but don't keep it open)\n",
    "        with h5py.File(h5_file, \"r\") as f:\n",
    "            self.length = len(f[\"r_c\"])\n",
    "            if fit_scalers:\n",
    "                # Load all data to fit scalers\n",
    "                x_data = np.stack([f[\"r_c\"][:], f[\"r_s\"][:], f[\"n_c\"][:], f[\"n_s\"][:]], axis=1)\n",
    "                y_data = f[\"cross_section\"][:]\n",
    "\n",
    "                self.x_scaler = TorchStandardScaler()\n",
    "                self.y_scaler = TorchStandardScaler()\n",
    "\n",
    "                self.x_scaler.fit(torch.tensor(x_data, dtype=torch.double))\n",
    "                self.y_scaler.fit(torch.tensor(y_data, dtype=torch.double))\n",
    "            else:\n",
    "                self.x_scaler = x_scaler\n",
    "                self.y_scaler = y_scaler\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.h5_file, \"r\") as f:\n",
    "            r_c = f[\"r_c\"][idx]\n",
    "            r_s = f[\"r_s\"][idx]\n",
    "            n_c = f[\"n_c\"][idx]\n",
    "            n_s = f[\"n_s\"][idx]\n",
    "            cross_section = f[\"cross_section\"][idx]\n",
    "\n",
    "        x = np.array([r_c, r_s, n_c, n_s]).reshape(1, -1)\n",
    "        y = np.array(cross_section).reshape(1, -1)\n",
    "\n",
    "        # Scale data using PyTorch scaler\n",
    "        x = self.x_scaler.transform(x).flatten()\n",
    "        y = self.y_scaler.transform(cross_section.reshape(1, -1)).flatten()\n",
    "\n",
    "        return x, y\n",
    "\n",
    "# Usage example\n",
    "h5_path = \"dataset.h5\"\n",
    "dataset = CoreShellDataset(h5_path)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = dataset.x_scaler\n",
    "y_scaler = dataset.y_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled x: tensor([[ -4.9413, -17.4347,  -0.5000,  -3.0000]], dtype=torch.float64)\n",
      "Original x: tensor([[0.5000, 0.7000, 1.5000, 2.0000]], dtype=torch.float64)\n",
      "Scaled y: tensor([[-2.4678e+00, -2.3735e+00, -2.9883e+00, -3.8345e+00, -2.7431e+00,\n",
      "         -3.2407e+00, -2.3504e+00, -3.6653e+00, -2.2468e+00, -2.8229e+00,\n",
      "         -3.3816e+00, -2.1936e+00, -2.0372e+00, -2.7896e+00, -2.4043e+00,\n",
      "         -2.0143e+00, -3.0892e+00, -2.4766e+00, -2.3372e+00, -3.6959e+00,\n",
      "         -2.9374e+00, -2.9175e+00, -2.3478e+00, -2.8056e+00, -3.6469e+00,\n",
      "         -3.8911e+00, -3.3523e+00, -3.1759e+00, -3.8020e+00, -2.0172e+00,\n",
      "         -2.1122e+00, -3.8589e+00, -2.9885e+00, -3.3926e+00, -3.0952e+00,\n",
      "         -4.9631e+00, -4.8822e+00, -5.3722e+00, -3.8877e+00, -5.5314e+00,\n",
      "         -4.4728e+00, -4.2314e+00, -7.1537e+00, -5.9778e+00, -6.5738e+00,\n",
      "         -4.6610e+00, -3.3515e+00, -6.2405e+00, -6.0409e+00, -3.1395e+00,\n",
      "         -4.8996e+00, -4.4153e+00, -5.1869e+00, -6.1766e+00, -4.6779e+00,\n",
      "         -4.3594e+00, -3.2400e+00, -4.4836e+00, -3.1353e+00, -5.4714e+00,\n",
      "         -5.3606e+00, -4.5881e+00, -3.2182e+00, -4.1420e+00, -3.3091e+00,\n",
      "         -4.5723e+00, -2.9439e+00, -5.6009e+00, -3.1311e+00, -3.0641e+00,\n",
      "         -3.4030e+00, -4.9877e+00, -2.7670e+00, -4.8023e+00, -3.0028e+00,\n",
      "         -3.5554e+00, -1.9055e+00, -2.7192e+00, -2.2545e+00, -4.0054e+00,\n",
      "         -1.7704e+00, -3.4545e+00, -1.9378e+00, -1.6151e+00, -3.4398e+00,\n",
      "         -2.1996e+00, -1.1955e+00, -1.7497e+00, -2.1882e+00, -1.8782e+00,\n",
      "         -1.9973e+00, -1.7159e+00, -1.0902e+00, -1.6552e+00, -1.2060e+00,\n",
      "         -1.1401e+00, -8.2671e-01, -2.1905e+00, -8.6844e-01, -1.5315e+00,\n",
      "         -8.8727e-01, -9.4359e-01, -1.6510e+00, -1.5613e+00, -9.5572e-01,\n",
      "         -8.9881e-01, -3.6960e-01, -1.6436e+00, -6.1243e-01, -1.5339e+00,\n",
      "         -1.4785e+00, -9.9095e-01, -1.5526e+00, -8.6213e-01, -1.1796e+00,\n",
      "         -1.0576e+00, -1.2330e+00, -7.8340e-01, -3.2414e-01, -5.8127e-01,\n",
      "         -1.2989e+00, -4.7673e-01, -7.2777e-01, -9.3047e-01, -5.1910e-01,\n",
      "         -1.0183e-01, -1.1706e+00, -6.6244e-01,  3.4850e-01, -3.5484e-01,\n",
      "         -1.1466e-02, -1.3569e+00,  3.3758e-01,  8.9534e-01, -1.1984e+00,\n",
      "         -2.8584e-01, -1.3800e+00,  3.6978e-01, -6.2732e-01,  1.1745e+00,\n",
      "         -1.3645e+00, -1.0400e-01, -1.3623e+00, -1.1047e+00,  1.4479e+00,\n",
      "         -1.0023e+00,  1.5969e+00, -1.0305e-01, -1.1733e-01, -1.1584e+00,\n",
      "          1.1974e-01,  3.2505e+00, -1.3411e+00,  3.7206e+00,  1.0479e+00,\n",
      "         -6.0377e-02,  1.1786e+00,  2.7782e+00,  4.7398e+00,  2.0005e+00,\n",
      "         -1.1561e-01, -2.5830e-02,  3.2555e+00, -1.2453e+00, -6.7660e-01,\n",
      "          1.7831e+00,  1.4640e+00, -1.9592e+00,  6.2439e+00,  1.8429e-01,\n",
      "          7.3359e+00,  8.6692e+00,  5.7653e+00, -1.6887e+00,  7.6711e+00,\n",
      "          3.2097e+00,  3.4473e+00, -5.5545e-01,  2.0641e+00,  6.2432e+00,\n",
      "          8.1008e+00, -2.6776e+00,  4.4537e+00,  7.3824e-01,  7.5665e+00,\n",
      "          1.2877e+01,  1.3670e+01, -1.9515e-01,  2.6860e-01, -2.0601e+00,\n",
      "          1.2579e+00,  1.0564e+01,  5.5992e+00,  1.2842e+00,  2.4450e+00,\n",
      "         -2.2990e+00, -3.1043e-01,  5.1087e+00,  1.5733e+01, -2.0697e+00,\n",
      "          1.2082e+01,  1.0635e+00, -1.0997e+00,  8.7740e+00,  1.6857e+01,\n",
      "          1.1317e+01,  8.4853e+00,  1.9707e+01,  7.3790e+00, -2.1150e-01,\n",
      "          1.9999e+01,  4.9370e+00,  9.3618e+00,  1.6487e+01,  6.6412e+00,\n",
      "          1.5602e+00,  1.0634e+01,  1.8208e+01,  1.8089e+01,  1.5486e+01,\n",
      "          6.7727e+00,  1.4960e+01,  1.0775e+01,  1.4971e+01,  2.0779e+00,\n",
      "          1.4296e+01,  1.7685e+00,  6.3439e+00, -1.3349e+00,  1.5838e+01,\n",
      "          2.8839e+01,  1.3997e+01,  5.8116e+00, -1.8144e+00,  2.6453e+01,\n",
      "          3.9211e+00,  1.4181e+01,  1.5161e+01,  6.5289e+00,  2.9044e+01,\n",
      "          3.4821e+01,  3.3565e+01,  4.1913e+00,  9.3731e+00,  1.4624e+01,\n",
      "          3.4264e+01,  3.6360e+01,  1.8522e+01,  7.0760e+00,  1.1517e+00]],\n",
      "       dtype=torch.float64)\n",
      "Original y: tensor([[0.9513, 0.9994, 0.6247, 0.1107, 0.7314, 0.4158, 0.9145, 0.1161, 0.9256,\n",
      "         0.5641, 0.2173, 0.8903, 0.9623, 0.5183, 0.7265, 0.9341, 0.3434, 0.6745,\n",
      "         0.7489, 0.0659, 0.4627, 0.4886, 0.7699, 0.5773, 0.2359, 0.1703, 0.4258,\n",
      "         0.5267, 0.3296, 0.9965, 0.9798, 0.4422, 0.7504, 0.6665, 0.7852, 0.3378,\n",
      "         0.4155, 0.3566, 0.7372, 0.4297, 0.6848, 0.7587, 0.2301, 0.4635, 0.3531,\n",
      "         0.6952, 0.9258, 0.3323, 0.3251, 0.9004, 0.4749, 0.5448, 0.3154, 0.0177,\n",
      "         0.3689, 0.4270, 0.7196, 0.3540, 0.7336, 0.0470, 0.0757, 0.3043, 0.7128,\n",
      "         0.4434, 0.6933, 0.3215, 0.8032, 0.0087, 0.7375, 0.7470, 0.6282, 0.1117,\n",
      "         0.7858, 0.0961, 0.6549, 0.4319, 0.9758, 0.6524, 0.7903, 0.0779, 0.9154,\n",
      "         0.1914, 0.7830, 0.8899, 0.0375, 0.5568, 0.9954, 0.6971, 0.4419, 0.5610,\n",
      "         0.4610, 0.5746, 0.8862, 0.5383, 0.7639, 0.7736, 0.9341, 0.0701, 0.8576,\n",
      "         0.4090, 0.7936, 0.7304, 0.2311, 0.2589, 0.6423, 0.6553, 0.9996, 0.0797,\n",
      "         0.7823, 0.1026, 0.1168, 0.4411, 0.0173, 0.4876, 0.2411, 0.3074, 0.1661,\n",
      "         0.4594, 0.7522, 0.5570, 0.0663, 0.5853, 0.4079, 0.2688, 0.5024, 0.7256,\n",
      "         0.1067, 0.3769, 0.8876, 0.5069, 0.6540, 0.0177, 0.7616, 0.9659, 0.0965,\n",
      "         0.4447, 0.0363, 0.6434, 0.2940, 0.8489, 0.0629, 0.4234, 0.0724, 0.1423,\n",
      "         0.7665, 0.1672, 0.7444, 0.3565, 0.3442, 0.1333, 0.3710, 0.9180, 0.1025,\n",
      "         0.9316, 0.4798, 0.2987, 0.4716, 0.6817, 0.9245, 0.5402, 0.2605, 0.2661,\n",
      "         0.6430, 0.1181, 0.1795, 0.4363, 0.3930, 0.0450, 0.8338, 0.2473, 0.8894,\n",
      "         0.9836, 0.7105, 0.0742, 0.8307, 0.4598, 0.4681, 0.1591, 0.3476, 0.6376,\n",
      "         0.7526, 0.0071, 0.4797, 0.2303, 0.6574, 0.9718, 0.9997, 0.1606, 0.1852,\n",
      "         0.0507, 0.2347, 0.7366, 0.4586, 0.2253, 0.2813, 0.0387, 0.1368, 0.3971,\n",
      "         0.8948, 0.0498, 0.6974, 0.1904, 0.0922, 0.5200, 0.8568, 0.6106, 0.4842,\n",
      "         0.9324, 0.4255, 0.1210, 0.9012, 0.3142, 0.4757, 0.7318, 0.3633, 0.1764,\n",
      "         0.4942, 0.7505, 0.7359, 0.6378, 0.3393, 0.6033, 0.4599, 0.5876, 0.1744,\n",
      "         0.5513, 0.1608, 0.2971, 0.0647, 0.5689, 0.9387, 0.5019, 0.2644, 0.0485,\n",
      "         0.8267, 0.2038, 0.4770, 0.4973, 0.2652, 0.8448, 0.9824, 0.9390, 0.1951,\n",
      "         0.3207, 0.4450, 0.9128, 0.9522, 0.5218, 0.2499, 0.1110]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Example of using the scalers on new data\n",
    "new_x = np.array([[0.5, 0.7, 1.5, 2.0]])\n",
    "scaled_x = x_scaler.transform(new_x)\n",
    "original_x = x_scaler.inverse_transform(scaled_x)\n",
    "\n",
    "new_y = np.random.rand(1, 250)  # Example y data with size 20\n",
    "scaled_y = y_scaler.transform(new_y)\n",
    "original_y = y_scaler.inverse_transform(scaled_y)\n",
    "\n",
    "print(\"Scaled x:\", scaled_x)\n",
    "print(\"Original x:\", original_x)\n",
    "print(\"Scaled y:\", scaled_y)\n",
    "print(\"Original y:\", original_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=250, output_dim=4, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 4])\n"
     ]
    }
   ],
   "source": [
    "test = torch.rand((32, 4))\n",
    "test_shape = test.shape\n",
    "print(test_shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def vector_batch(x_pred):\n",
    "\n",
    "\n",
    "    batch_shape = x_pred.shape\n",
    "    # [r_c, r_s, n_c, n_s]\n",
    "    y_pred_temp = []\n",
    "\n",
    "    for i in range(batch_shape[0]):\n",
    "        x_batch = x_pred[i, :]\n",
    "        r_c_i, r_s_i, n_c_i, n_s_i = x_batch[0], x_batch[1], x_batch[2], x_batch[3]\n",
    "\n",
    "        #print(\"x\", x_batch)\n",
    "\n",
    "        y_batch = pmd.farfield.cross_sections(\n",
    "            k0=k0,\n",
    "            r_c=r_c_i,\n",
    "            eps_c=n_c_i ** 2,\n",
    "            r_s=r_s_i,\n",
    "            eps_s=n_s_i ** 2,\n",
    "            eps_env=1,\n",
    "        )[\"q_sca\"]\n",
    "\n",
    "\n",
    "\n",
    "        # y_batch = y_batch.to(dtype=torch.double)  # Set dtype\n",
    "        # y_batch[torch.isnan(y_batch)] = 0  # Replace NaNs with zero\n",
    "\n",
    "        #print(\"y\", y_batch[:10])\n",
    "        y_pred_temp.append(y_batch)\n",
    "\n",
    "    # print(y_pred_temp)\n",
    "\n",
    "    y_pred = torch.stack(y_pred_temp)\n",
    "\n",
    "\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, num_epochs=20, lr=1e-5, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "    model.to(device)\n",
    "    model.double()\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # Inverse model\n",
    "            x_pred = model(y_batch)\n",
    "            #print(x_pred.shape)\n",
    "            # Forward model\n",
    "\n",
    "            x_pred_scaled = x_scaler.inverse_transform(x_pred)\n",
    "\n",
    "            y_pred = vector_batch(x_pred_scaled)#\n",
    "\n",
    "            y_pred_scaled = y_scaler.transform(y_pred)\n",
    "            # print(\"y test\", y_batch[0, :10])\n",
    "            # print(\"vVv Inverse network vVv\")\n",
    "            # print(\"x pred\", x_pred_scaled[0, :])\n",
    "            # print(\"vVv Forward Mie solver vVv\")\n",
    "            # print(\"y pred\", y_pred[0, :10])\n",
    "\n",
    "            loss = criterion(y_pred_scaled, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_32088\\1531130095.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "h5_path = \"dataset.h5\"\n",
    "\n",
    "train_dataset = CoreShellDataset(h5_path)\n",
    "# scaler = train_dataset.scaler  # Save scaler for later use\n",
    "\n",
    "# Create DataLoader for batch processing\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking about 1min 30s on my laptop per epoc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_32088\\1531130095.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n",
      "C:\\Users\\okcj1g19\\AppData\\Local\\Temp\\ipykernel_32088\\1531130095.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = torch.tensor(data, dtype=torch.double)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 28.032310\n",
      "Epoch [2/50], Loss: 28.021012\n",
      "Epoch [3/50], Loss: 28.010971\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m mlp_model \u001b[38;5;241m=\u001b[39m MLP()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[33], line 59\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, dataloader, num_epochs, lr, device)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m#print(x_pred.shape)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Forward model\u001b[39;00m\n\u001b[0;32m     57\u001b[0m x_pred_scaled \u001b[38;5;241m=\u001b[39m x_scaler\u001b[38;5;241m.\u001b[39minverse_transform(x_pred)\n\u001b[1;32m---> 59\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mvector_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_pred_scaled\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     61\u001b[0m y_pred_scaled \u001b[38;5;241m=\u001b[39m y_scaler\u001b[38;5;241m.\u001b[39mtransform(y_pred)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# print(\"y test\", y_batch[0, :10])\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# print(\"vVv Inverse network vVv\")\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# print(\"x pred\", x_pred_scaled[0, :])\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# print(\"vVv Forward Mie solver vVv\")\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# print(\"y pred\", y_pred[0, :10])\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[33], line 14\u001b[0m, in \u001b[0;36mvector_batch\u001b[1;34m(x_pred)\u001b[0m\n\u001b[0;32m     10\u001b[0m r_c_i, r_s_i, n_c_i, n_s_i \u001b[38;5;241m=\u001b[39m x_batch[\u001b[38;5;241m0\u001b[39m], x_batch[\u001b[38;5;241m1\u001b[39m], x_batch[\u001b[38;5;241m2\u001b[39m], x_batch[\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#print(\"x\", x_batch)\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m y_batch \u001b[38;5;241m=\u001b[39m \u001b[43mpmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfarfield\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_sections\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mk0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_c_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_c\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_c_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mr_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr_s_i\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_s_i\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq_sca\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# y_batch = y_batch.to(dtype=torch.double)  # Set dtype\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# y_batch[torch.isnan(y_batch)] = 0  # Replace NaNs with zero\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#print(\"y\", y_batch[:10])\u001b[39;00m\n\u001b[0;32m     29\u001b[0m y_pred_temp\u001b[38;5;241m.\u001b[39mappend(y_batch)\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\farfield.py:48\u001b[0m, in \u001b[0;36mcross_sections\u001b[1;34m(k0, r_c, eps_c, r_s, eps_s, eps_env, an, bn, n_max)\u001b[0m\n\u001b[0;32m     46\u001b[0m m_s \u001b[38;5;241m=\u001b[39m n_s \u001b[38;5;241m/\u001b[39m n_env\n\u001b[0;32m     47\u001b[0m a_n \u001b[38;5;241m=\u001b[39m an(x, y, n, m_c, m_s)\n\u001b[1;32m---> 48\u001b[0m b_n \u001b[38;5;241m=\u001b[39m \u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_c\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_s\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# - geometric cross section\u001b[39;00m\n\u001b[0;32m     51\u001b[0m cs_geo \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m r_s\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\coreshell.py:38\u001b[0m, in \u001b[0;36mbn\u001b[1;34m(x, y, n, m1, m2)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbn\u001b[39m(x, y, n, m1, m2):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m         m2 \u001b[38;5;241m*\u001b[39m psi(y, n) \u001b[38;5;241m*\u001b[39m (psi_der(m2 \u001b[38;5;241m*\u001b[39m y, n) \u001b[38;5;241m-\u001b[39m Bn(x, n, m1, m2) \u001b[38;5;241m*\u001b[39m chi_der(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;241m-\u001b[39m psi_der(y, n) \u001b[38;5;241m*\u001b[39m (psi(m2 \u001b[38;5;241m*\u001b[39m y, n) \u001b[38;5;241m-\u001b[39m Bn(x, n, m1, m2) \u001b[38;5;241m*\u001b[39m chi(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     37\u001b[0m     ) \u001b[38;5;241m/\u001b[39m (\n\u001b[1;32m---> 38\u001b[0m         m2 \u001b[38;5;241m*\u001b[39m xi(y, n) \u001b[38;5;241m*\u001b[39m (\u001b[43mpsi_der\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m Bn(x, n, m1, m2) \u001b[38;5;241m*\u001b[39m chi_der(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;241m-\u001b[39m xi_der(y, n) \u001b[38;5;241m*\u001b[39m (psi(m2 \u001b[38;5;241m*\u001b[39m y, n) \u001b[38;5;241m-\u001b[39m Bn(x, n, m1, m2) \u001b[38;5;241m*\u001b[39m chi(m2 \u001b[38;5;241m*\u001b[39m y, n))\n\u001b[0;32m     40\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\special.py:246\u001b[0m, in \u001b[0;36mpsi_der\u001b[1;34m(z, n)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpsi_der\u001b[39m(z, n):\n\u001b[1;32m--> 246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Jn(n, z) \u001b[38;5;241m+\u001b[39m z \u001b[38;5;241m*\u001b[39m \u001b[43mdJn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\special.py:119\u001b[0m, in \u001b[0;36mdJn\u001b[1;34m(n, z)\u001b[0m\n\u001b[0;32m    117\u001b[0m n \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(n, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint)\n\u001b[0;32m    118\u001b[0m z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(z)\n\u001b[1;32m--> 119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_AutoDiffdJn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\okcj1g19\\AppData\\Local\\anaconda3\\envs\\pyMieDiff\\Lib\\site-packages\\torch\\autograd\\function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    583\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\okcj1g19\\docs_offline\\miediff\\pymiediff\\special.py:76\u001b[0m, in \u001b[0;36m_AutoDiffdJn.forward\u001b[1;34m(n, z)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(n, z):\n\u001b[0;32m     75\u001b[0m     n_np, z_np \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy(), z\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m---> 76\u001b[0m     result \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(\u001b[43mspherical_jn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mderivative\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\okcj1g19\\AppData\\Local\\anaconda3\\envs\\pyMieDiff\\Lib\\site-packages\\scipy\\special\\_spherical_bessel.py:90\u001b[0m, in \u001b[0;36mspherical_jn\u001b[1;34m(n, z, derivative)\u001b[0m\n\u001b[0;32m     88\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m derivative:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_spherical_jn_d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _spherical_jn(n, z)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mlp_model = MLP()\n",
    "train_model(mlp_model, dataloader, num_epochs=50, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample from the dataset\n",
    "x_sample, y_sample = train_dataset[0]  # Example input\n",
    "x_sample = x_sample.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "# Run inference\n",
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = mlp_model(x_sample)\n",
    "\n",
    "# Convert prediction back to original scale\n",
    "y_pred_original = scaler.inverse_transform(y_pred.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyMieDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
